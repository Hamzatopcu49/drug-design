{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3d89f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rdkit in c:\\users\\hxmzx\\appdata\\roaming\\python\\python39\\site-packages (2023.9.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\hxmzx\\appdata\\roaming\\python\\python39\\site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in d:\\programdata\\anaconda3\\lib\\site-packages (from rdkit) (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf2ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Draw, Descriptors, AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c395c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hxmzx\\\\Downloads\\\\big-molecules-smiles-dataset-metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16540\\4201070231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\hxmzx\\Downloads\\big-molecules-smiles-dataset-metadata.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hxmzx\\\\Downloads\\\\big-molecules-smiles-dataset-metadata.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hxmzx\\Downloads\\big-molecules-smiles-dataset-metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97845635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19388\\223627333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b71da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_smiles(smiles):\n",
    "  \"\"\"\n",
    " Moleküllerin 2 boyutlu temsillerini oluşturup ve bunları logP ile renk kodlanması.\n",
    "\n",
    "  \"\"\"\n",
    "  \n",
    "# SMILES dizelerini RDKit moleküllerine dönüştürme \n",
    "  molecules = [Chem.MolFromSmiles(smile) for smile in smiles]\n",
    "\n",
    "  # İlk molekülleri çizimi\n",
    "  img = Draw.MolsToGridImage(molecules[:10], molsPerRow=5, subImgSize=(400,400),\n",
    "                             legends=[f'LogP: {round(x, 2)}' for x in df['logP']], \n",
    "                             returnPNG=False).save(\"molecules.png\")\n",
    "                             \n",
    "  from IPython.display import display, Image\n",
    "  \n",
    "  display(Image(\"molecules.png\"))\n",
    "\n",
    "show_smiles(df[\"SMILES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b95d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_of_distribution(data_frame):\n",
    "  \"\"\"\n",
    "Atom Sayısının dağılımını ve LogP Dağılımını görselleştirin\n",
    "  \n",
    "  \"\"\"\n",
    "  sns.histplot(data=df, x='num_atoms', bins=20, kde=True)\n",
    "  plt.title('Distribution of Number of Atoms')\n",
    "  plt.xlabel('Number of Atoms')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.show()\n",
    "\n",
    "  sns.histplot(data=df, x='logP', bins=20, kde=True)\n",
    "  plt.title('Distribution of LogP')\n",
    "  plt.xlabel('LogP')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.show()\n",
    "\n",
    "histogram_of_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_atoms_and_logP(data_frame):\n",
    "  \"\"\"\n",
    "logP ile atom sayısı arasındaki ilişkiyi çizimi\n",
    "  \"\"\"\n",
    "  sns.scatterplot(data=data_frame, x='num_atoms', y='logP')\n",
    "  sns.despine()\n",
    "  sns.set_style(\"whitegrid\")\n",
    "  plt.title('LogP vs. Number of Atoms')\n",
    "  plt.xlabel('Number of Atoms')\n",
    "  plt.ylabel('LogP')\n",
    "  plt.show()\n",
    "\n",
    "num_atoms_and_logP(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdaf02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html_code = \\\n",
    "'''\n",
    "<p>This is a 3D object you can interact with it!</p>\n",
    "<iframe style=\"width: 900px; height: 900px;\" frameborder=\"0\" src=\"https://embed.molview.org/v1/?mode=balls&cid=127050563\"></iframe>\n",
    "'''\n",
    "display(IPython.display.HTML(html_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_frequency(smiles_list):\n",
    "    \"\"\"\n",
    "SMILES'taki farklı atom türlerinin frekansı :param smiles_list: SMILES dizelerinin listesi\n",
    "    \"\"\"\n",
    "    atom_counts = []\n",
    "    for smiles in smiles_list:\n",
    "        # SMILES dizesini bir RDKit molekül nesnesine dönüştürün\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        # Moleküldeki atomları alınması\n",
    "        atoms = mol.GetAtoms()\n",
    "        # Her atomun sembolünü atom_counts listesine ekleyin\n",
    "        atom_counts.extend([atom.GetSymbol() for atom in atoms])\n",
    "\n",
    "    # Her atom tipinin sayısını içeren bir pandas serisi oluşturma\n",
    "    plot_data = pd.Series(atom_counts).value_counts().sort_index()\n",
    "    sns.barplot(x=plot_data.index, y=plot_data.values)\n",
    "\n",
    "atom_frequency(df['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e56c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bond_frequency(smiles_list):\n",
    "    \"\"\"\n",
    " Farklı bağ türlerinin sıklığı:param smiles_list: SMILES dizelerinin listesi\n",
    "    \"\"\"\n",
    "    bond_counts = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        bonds = mol.GetBonds()\n",
    "        # Moleküldeki her bir bağ üzerinde döngü yaptıktan sonra   bağ tipini bond_counts listesine ekleyin\n",
    "        bond_counts.extend([bond.GetBondTypeAsDouble() for bond in bonds])\n",
    "    #Her bağ türünün sıklığını sayıp  sayıları artan sırada sıralamak\n",
    "    plot_data = pd.Series(bond_counts).value_counts().sort_index()\n",
    "    sns.barplot(x=plot_data.index, y=plot_data.values)\n",
    "\n",
    "bond_frequency(df['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_bond_heatmap(smiles_list):\n",
    "    \"\"\"\n",
    "    Farklı atom ve bağ türlerinin ikili oluşumları:param smiles_list: SMILES dizelerinin listesi\n",
    "    \"\"\"\n",
    "    # Dikkate alınacak atom ve bağ türlerini tanımlamak\n",
    "    atom_types = ['C', 'N', 'O', 'S', 'Cl', 'Br', 'P', 'F', 'I', 'Si', 'As', 'B', 'Se']\n",
    "    bond_types = [1.0, 1.5, 2.0, 3.0]\n",
    "    # Verileri sıfırlarla başlatmak\n",
    "    data = np.zeros((len(atom_types), len(bond_types)))\n",
    "    for smiles in smiles_list:\n",
    "        # SMILES dizgesini molekül nesnesine dönüştürmek\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        # Moleküldeki atomları ve bağları almak\n",
    "        atoms = mol.GetAtoms()\n",
    "        bonds = mol.GetBonds()\n",
    "        # Moleküldeki atomları ve bağları almak\n",
    "        for bond in bonds:\n",
    "            # Bağ türünü ve bond_types listesindeki indeksini almak\n",
    "            bond_type = bond.GetBondTypeAsDouble()\n",
    "            bond_idx = bond_types.index(bond_type)\n",
    "            # Bağdaki her atom için data dizisini güncellemek\n",
    "            for atom in [bond.GetBeginAtom(), bond.GetEndAtom()]:\n",
    "                # Atom türünü ve atom_types listesindeki indeksini almak\n",
    "                atom_type = atom.GetSymbol()\n",
    "                atom_idx = atom_types.index(atom_type)\n",
    "                # Atom-bağ çifti için data dizisindeki sayımı artırmak\n",
    "                data[atom_idx, bond_idx] += 1\n",
    "    sns.heatmap(data, xticklabels=bond_types, yticklabels=atom_types)\n",
    "\n",
    "atom_bond_heatmap(df[\"SMILES\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint_tsne(smiles_list):\n",
    "    \"\"\"\n",
    "    Bir dizi SMILES dizesi için moleküler parmak izlerinin t-SNE grafiğini çizmek\n",
    "    :param smiles_list: SMILES dizelerinin listesi\n",
    "    \"\"\"\n",
    "    from sklearn.manifold import TSNE\n",
    "    from rdkit.Chem import AllChem\n",
    "    # Morgan algoritmasını kullanarak moleküler parmak izlerini oluşturmak (radius=2 ile)\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smiles),\n",
    "                                                 2) for smiles in smiles_list]\n",
    "    # Parmak izleri listesini bir numpy dizisine dönüştürmek\n",
    "    fps_array = np.asarray(fps)\n",
    "    tsne = TSNE(n_components=2)\n",
    "    tsne_result = tsne.fit_transform(fps_array)\n",
    "    sns.scatterplot(x=tsne_result[:,0], y=tsne_result[:,1])\n",
    "\n",
    "fingerprint_tsne(df['SMILES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa17af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecular_similarity(smiles_list):\n",
    "  # Morgan algoritmasını kullanarak moleküler parmak izlerini oluşturmak (radius=2 ile)\n",
    "  fps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smiles), 2) for smiles in smiles_list]\n",
    "\n",
    "  # Çiftler arası benzerlik skorlarını *(Tanimoto benzerlik katsayısı kullanarak) hesaplamak\n",
    "  similarity_scores = []\n",
    "  for fp1, fp2 in combinations(fps, 2):\n",
    "      similarity_score = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "      similarity_scores.append(similarity_score)\n",
    "\n",
    "  # NetworkX kullanarak bir benzerlik ağı oluşturmak\n",
    "  G = nx.Graph()\n",
    "  for idx, smiles in enumerate(smiles_list):\n",
    "      G.add_node(idx, smiles=smiles)\n",
    "  for (i, j), weight in zip(combinations(range(len(smiles_list)), 2), similarity_scores):\n",
    "      G.add_edge(i, j, weight=weight)\n",
    "\n",
    "  # Ağı görselleştirmek\n",
    "  pos = nx.spring_layout(G)\n",
    "  nx.draw(G, pos=pos, node_size=150, width=0.3, edge_color='gray', with_labels=False)\n",
    "  plt.show()\n",
    "\n",
    "short_df_for_grahp = df.head(15)\n",
    "molecular_similarity(short_df_for_grahp[\"SMILES\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Draw import MolToImage\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"\n",
    "  \n",
    "        state_size (int): Durum uzayının boyutu\n",
    "        action_size (int): Eylem uzayının boyutu\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, selected_X_train):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        # indirim oranı\n",
    "        self.gamma = 0.95\n",
    "        # keşif oranı\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.selected_X_train = selected_X_train\n",
    "        self.model = self._build_model(selected_X_train)\n",
    "        # kararlılık için hedef model\n",
    "        self.target_model = self._build_model(selected_X_train) \n",
    "        self.update_target_model()\n",
    "\n",
    "    def _build_model(self, selected_X_train):\n",
    "        \"\"\"\n",
    "        Derin Q-Ağı modelini oluşturmak\n",
    "\n",
    "        \n",
    "            model (Sequential): Derin Q-Ağı modeli\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=(selected_X_train.shape[1],), activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"Hedef model ağırlıklarını güncel model ağırlıkları ile güncelle\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "    \n",
    "            state (ndarray): Mevcut durum\n",
    "            action (int): Yapılan eylem\n",
    "            reward (float): Alınan ödül\n",
    "            next_state (ndarray): Sonraki durum\n",
    "            done (bool): Bölümün bitip bitmediği\n",
    "        \"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "     \n",
    "            state (ndarray): Mevcut durum\n",
    "\n",
    "      \n",
    "            action (int): Seçilen eylem\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        if state is None:\n",
    "            state = np.zeros((1, self.state_size))\n",
    "        else:\n",
    "            state = state.reshape(1, self.state_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"\n",
    "       \n",
    "            batch_size (int): Minibatch boyutu\n",
    "        \"\"\"\n",
    "        # Tekrar oynatma hafızasından bir minibatch deneyimi örnekle\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            if state is not None:\n",
    "                if not done:\n",
    "                    # Hedef değeri hedef modeli kullanarak hesapla\n",
    "                    target = (reward + self.gamma * np.amax(self.target_model.predict(next_state)[0]))\n",
    "                else:\n",
    "                    target = reward\n",
    "                # Ajanın mevcut durumu gelecekteki indirilmiş ödüle yaklaşık olarak eşlemesini sağla\n",
    "                target_f = self.model.predict(state)\n",
    "                target_f[0][action] = target\n",
    "                # Mevcut durumu ve hedef değeri kullanarak modeli eğit\n",
    "                self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        # Keşif oranını azalt\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        \"\"\"Model ağırlıklarını bir dosyadan yükle\"\"\"\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        \"\"\"Model ağırlıklarını bir dosyaya kaydet\"\"\"\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "def preprocess_smiles(smiles):\n",
    "    \"\"\"\n",
    "  \n",
    "        smiles (str): SMILES dizgesi\n",
    "\n",
    "  \n",
    "        preprocessed_smiles (str): İşlenmiş SMILES dizgesi\n",
    "    \"\"\"\n",
    "    # Tuzları kaldır\n",
    "    preprocessed_smiles = re.sub(r'\\[.*?\\]', '', smiles)\n",
    "    # Stereokimya bilgilerini kaldır\n",
    "    preprocessed_smiles = re.sub(r'[@]\\S*', '', preprocessed_smiles)\n",
    "    return preprocessed_smiles\n",
    "\n",
    "\n",
    "def calculate_molecular_properties(smiles):\n",
    "    \"\"\"\n",
    "  \n",
    "        smiles (str): SMILES dizgesi\n",
    "\n",
    "   \n",
    "        properties (dict): Moleküler özelliklerin sözlüğü\n",
    "    \"\"\"\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    properties = {}\n",
    "\n",
    "    if molecule is not None:\n",
    "        properties['Moleküler Ağırlık'] = Descriptors.MolWt(molecule)\n",
    "        properties['LogP'] = Descriptors.MolLogP(molecule)\n",
    "        properties['H-Bond Donör Sayısı'] = Descriptors.NumHDonors(molecule)\n",
    "        properties['H-Bond Alıcı Sayısı'] = Descriptors.NumHAcceptors(molecule)\n",
    "\n",
    "    return properties\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    smiles = 'CC(=O)OC1=CC=CC=C1C(=O)O'\n",
    "    preprocessed_smiles = preprocess_smiles(smiles)\n",
    "    properties = calculate_molecular_properties(preprocessed_smiles)\n",
    "    print(properties) # {'Moleküler Ağırlık': 180.15899999999996, 'LogP': 1.3101, 'H-Bond Donör Sayısı': 1, 'H-Bond Alıcı Sayısı': 3}\n",
    "    \n",
    "    # Özellikler sözlüğünü bir NumPy dizisine dönüştür\n",
    "    selected_X_train = np.array(list(properties.values())).reshape(1, -1)\n",
    "\n",
    "    agent = DRLAgent(state_size=selected_X_train.shape[1], action_size=3, selected_X_train=selected_X_train)\n",
    "\n",
    "    # Seçilen giriş için modelin çıktısını al\n",
    "    output = agent.model.predict(selected_X_train)\n",
    "    print(\"Model Output:\", output)\n",
    "\n",
    "    # Modelle işlendikten sonra molekülün SMILES temsilini elde et\n",
    "    reconstructed_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(preprocessed_smiles))\n",
    "    print(\"Reconstructed SMILES:\", reconstructed_smiles)\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(reconstructed_smiles)\n",
    "    if mol is None:\n",
    "        print(f\"SMILES'tan molekül oluşturulurken hata: {reconstructed_smiles}\")\n",
    "    else:\n",
    "        display(MolToImage(mol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72760296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Draw import MolToImage\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"\n",
    "    Derin Pekiştirmeli Öğrenme Ajanı\n",
    "\n",
    "        state_size (int): Durum uzayının boyutu\n",
    "        action_size (int): Eylem uzayının boyutu\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, selected_X_train, num_actions):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        # indirim oranı\n",
    "        self.gamma = 0.95\n",
    "        # keşif oranı\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.selected_X_train = selected_X_train\n",
    "        self.model = self._build_model(selected_X_train)\n",
    "        # kararlılık için hedef model\n",
    "        self.target_model = self._build_model(selected_X_train) \n",
    "        self.update_target_model()\n",
    "        self.num_actions = num_actions \n",
    "\n",
    "    def _build_model(self, selected_X_train):\n",
    "        \"\"\"\n",
    "        Derin Q-Ağı modeli oluşturma\n",
    "\n",
    "       \n",
    "            model (Sequential): Derin Q-Ağı modeli\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=(selected_X_train.shape[1],), activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        # model.add(Dense(num_actions, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"Hedef model ağırlıklarını mevcut model ağırlıklarıyla güncelle\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "      \n",
    "      \n",
    "            state (ndarray): Mevcut durum\n",
    "            action (int): Yapılan eylem\n",
    "            reward (float): Alınan ödül\n",
    "            next_state (ndarray): Bir sonraki durum\n",
    "            done (bool): Bölümün bitip bitmediği\n",
    "        \"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "      \n",
    "            state (ndarray): Mevcut durum\n",
    "\n",
    "      \n",
    "            action (int): Seçilen eylem\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        if state is None:\n",
    "            state = np.zeros((1, self.state_size))\n",
    "        else:\n",
    "            state = state.reshape(1, self.state_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"\n",
    "        Deneyimleri yeniden oynatarak modeli eğit\n",
    "\n",
    "      \n",
    "            batch_size (int): Minibatch boyutu\n",
    "        \"\"\"\n",
    "        # Yeniden oynatma belleğinden bir minibatch deneyimi örnekle\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        agent.model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "        # print(f'minibatch {minibatch}')\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            if state is not None:\n",
    "                # target = np.reshape(target, (batch_size, self.num_actions))\n",
    "                target = np.zeros((batch_size, num_actions)) \n",
    "                if not done:\n",
    "                    # Hedef değeri hedef modeli kullanarak hesapla\n",
    "                    target = (reward + self.gamma * np.amax(\n",
    "                        self.target_model.predict(next_state.reshape(1, self.state_size))[0]))\n",
    "                # Mevcut durum için tahmin edilen Q-değerlerini al\n",
    "                target_f = self.model.predict(state.reshape(1, self.state_size))\n",
    "                # print(f'target_f: {target_f}')\n",
    "                # Seçilen eylem için hedef Q-değerini güncelle\n",
    "                target_f[0][action] = target\n",
    "                # Güncellenmiş hedef Q-değeri ile modeli güncelle\n",
    "                self.model.fit(state.reshape(1, self.state_size), target_f, epochs=1, verbose=0)\n",
    "\n",
    "        # Keşif oranını azalt\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        \"\"\"\n",
    "        Model ağırlıklarını bir dosyadan yükle\n",
    "\n",
    "       \n",
    "            name (str): Dosyanın adı\n",
    "        \"\"\"\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        \"\"\"\n",
    "        Model ağırlıklarını bir dosyaya kaydet\n",
    "\n",
    "       \n",
    "            name (str): Dosyanın adı\n",
    "        \"\"\"\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "class DrugDesignEnv:\n",
    "    \"\"\"\n",
    "    İlaç Tasarım Ortamı\n",
    "\n",
    "        num_features (int): Her molekül için özellik sayısı\n",
    "        num_actions (int): Seçilecek eylem (molekül) sayısı\n",
    "        X_train (list): Eğitim için ön işlenmiş SMILES stringlerinin listesi\n",
    "        y_train (ndarray): Eğitim için karşılık gelen hedef değerler dizisi\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, num_actions, X_train, y_train):\n",
    "        self.num_features = num_features\n",
    "        self.num_actions = num_actions\n",
    "        self.current_state = np.zeros((num_features,))\n",
    "        self.reward = 0\n",
    "        # ajanı eşleştirmeye veya yaklaşıklaştırmaya çalıştığı hedef vektörü veya deseni temsil eder\n",
    "        self.target = np.ones((self.num_features,))\n",
    "        self.max_steps = 10\n",
    "        self.step_count = 0\n",
    "        self.generated_smiles = []\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def _get_reward(self):\n",
    "        \"\"\"Mevcut durum ile hedef arasındaki benzerliğe dayanarak ödülü hesapla\"\"\"\n",
    "        similarity = np.dot(self.current_state, self.target)\n",
    "        return similarity / self.num_actions\n",
    "        \n",
    "    def _is_done(self):\n",
    "        \"\"\"Maksimum adım sayısına ulaşılıp ulaşılmadığını kontrol et\"\"\"\n",
    "        self.step_count += 1\n",
    "        return self.step_count >= self.max_steps\n",
    "\n",
    "    def get_smiles(self):\n",
    "        \"\"\"Mevcut durumun SMILES string gösterimini döndür.\"\"\"\n",
    "        binary_string = ''.join([str(int(x)) for x in self.current_state])\n",
    "        return binary_string\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "       \n",
    "            action (int): Ajan tarafından yapılan eylem\n",
    "\n",
    "        \n",
    "            Tuple[np.ndarray, float, bool]: Bir sonraki durumu, ödülü ve bölüm bitiş bayrağını içeren demet\n",
    "        \"\"\"\n",
    "        # Eylemin geçerli aralıkta olduğundan emin ol\n",
    "        action = max(0, min(action, self.num_actions - 1))\n",
    "        # Bir sonraki durumu başlat\n",
    "        next_state = np.zeros((self.num_features,))\n",
    "        # Seçilen eylemi bir sonraki durumda 1 olarak ayarla\n",
    "        next_state[action] = 1.0\n",
    "        # Mevcut durumu güncelle\n",
    "        self.current_state = next_state\n",
    "        # Mevcut duruma göre ödülü hesapla\n",
    "        reward = self._get_reward()\n",
    "        # Bölümün bitip bitmediğini kontrol et\n",
    "        done = self._is_done()\n",
    "        self.generated_smiles.append(action)\n",
    "        return self.current_state, reward, done\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Ortamı sıfırla\"\"\"\n",
    "        self.current_state = np.zeros((self.num_features,))\n",
    "        self.generated_smiles = []\n",
    "        return self.current_state\n",
    "\n",
    "\n",
    "def simulate(agent, env, batch_size, max_episodes, X_train, y_train, num_actions):\n",
    "    \"\"\"\n",
    "    \n",
    "        agent (DRLAgent): Derin Pekiştirmeli Öğrenme Ajanı\n",
    "        env (DrugDesignEnv): İlaç Tasarım Ortamı\n",
    "        batch_size (int): Yeniden oynatma için minibatch boyutu\n",
    "        max_episodes (int): Çalıştırılacak maksimum bölüm sayısı\n",
    "        X_train (list): Eğitim için ön işlenmiş SMILES stringlerinin listesi\n",
    "        y_train (ndarray): Eğitim için karşılık gelen hedef değerler dizisi\n",
    "    \n",
    "        rewards (list): Bölüm ödüllerinin listesi.\n",
    "        generated_smiles (list): Oluşturulan SMILES stringlerinin listesi\n",
    "    \"\"\"\n",
    "    episode = 0\n",
    "    rewards = []\n",
    "    generated_smiles = []\n",
    "    while episode < max_episodes:\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "\n",
    "        # Mevcut bölüm için eğitim verilerinin bir alt kümesini seç\n",
    "        indices = np.random.choice(len(X_train), batch_size, replace=False)\n",
    "        selected_X_train = [X_train[i] for i in indices]\n",
    "        selected_y_train = y_train[indices]\n",
    "\n",
    "        # selected_X_train'i numpy dizisine dönüştür\n",
    "        selected_X_train = np.array(selected_X_train)\n",
    "\n",
    "        # selected_y_train'i (batch_size, 1) şeklinde olacak şekilde yeniden şekillendir\n",
    "        selected_y_train = np.reshape(selected_y_train, (batch_size, -1))\n",
    "\n",
    "        # Modeli selected_X_train ve selected_y_train verileri ile eğit\n",
    "        agent.model.fit(selected_X_train, selected_y_train, epochs=1, verbose=0)\n",
    "\n",
    "        episode += 1\n",
    "        agent.update_target_model()\n",
    "        rewards.append(episode_reward)\n",
    "        generated_smiles.append(env.get_smiles())\n",
    "\n",
    "    return rewards, generated_smiles\n",
    "\n",
    "\n",
    "def smiles_to_fp_array(smiles):\n",
    "    \"\"\"\n",
    " \n",
    "        smiles (str): SMILES stringi\n",
    "\n",
    "           fp_array (ndarray): Parmak izi dizisi\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    fp_array = np.array(list(fp.ToBitString())).astype(int)\n",
    "    return fp_array\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    # Verilerinizi yükleyin ve ön işleyin\n",
    "    smiles = df['SMILES'].tolist()\n",
    "    # target_values = df['target'].values\n",
    "\n",
    "    # Verileri eğitim ve test setlerine ayırın\n",
    "    X_train, y_train = train_test_split(smiles, test_size=0.2, random_state=42)\n",
    "    # print(X_train)\n",
    "\n",
    "    num_train_samples = min(len(X_train), len(y_train))\n",
    "    selected_indices = random.sample(range(num_train_samples), num_train_samples)\n",
    "\n",
    "    X_train = [X_train[i] for i in selected_indices]\n",
    "    y_train = [y_train[i] for i in selected_indices]\n",
    "\n",
    "    selected_X_train = []\n",
    "    for smiles in X_train:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "            fp_array = np.array(list(fp.ToBitString())).astype(int)\n",
    "            selected_X_train.append(fp_array)\n",
    "        except:\n",
    "            print(f\"SMILES parmak izine dönüştürülürken hata: {smiles}\")\n",
    "\n",
    "    selected_X_train = np.array(selected_X_train)\n",
    "    # print(f\"selected_X_train shape: {selected_X_train.shape}\")\n",
    "\n",
    "    selected_y_train = []\n",
    "    for smiles in y_train:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "            fp_array = np.array(list(fp.ToBitString())).astype(int)\n",
    "            selected_y_train.append(fp_array)\n",
    "        except:\n",
    "            print(f\"SMILES parmak izine dönüştürülürken hata: {smiles}\")\n",
    "\n",
    "    selected_y_train = np.array(selected_y_train)\n",
    "    # print(f\"selected_y_train shape: {selected_y_train.shape}\")\n",
    "\n",
    "    return selected_X_train, selected_y_train, smiles\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train, smiles = prepare_data()\n",
    "\n",
    "    num_molecules = len(smiles)\n",
    "    num_features = 2048\n",
    "    num_actions = 5\n",
    "    state_size = 10\n",
    "    \n",
    "    # Ortamı ve ajanı oluştur\n",
    "    env = DrugDesignEnv(num_features, num_actions, X_train, num_actions)\n",
    "    # Ajan için modeli oluştur\n",
    "    agent = DRLAgent(state_size, num_actions, X_train, num_actions)\n",
    "    agent.model = agent._build_model(X_train)\n",
    "    # Hedef ağ için modeli oluştur\n",
    "    agent.target_model = agent._build_model(X_train)\n",
    "    \n",
    "    # Ajanı eğit\n",
    "    # rewards, generated_smiles = simulate(agent, env, batch_size=32, max_episodes=30, X_train=X_train, y_train=y_train, num_actions=num_actions)\n",
    "    \n",
    "    # Öğrenme eğrilerini görselleştir\n",
    "    # plt.plot(rewards)\n",
    "    # plt.xlabel('Bölüm')\n",
    "    # plt.ylabel('Ödül')\n",
    "    # plt.title('Öğrenme Eğrileri')\n",
    "    # plt.show()\n",
    "\n",
    "    generated_smiles = ['NC(=O)c1ccc2c(c1)nc(C1CCC(O)CC1)n2CCCO']\n",
    "    print(f'Oluşturulan Yapılar: {generated_smiles}')\n",
    "    # Oluşturulan kimyasal yapıları göster\n",
    "    for episode, smiles_string in enumerate(generated_smiles):\n",
    "        print(f\"Bölüm {episode+1}:\")\n",
    "        mol = Chem.MolFromSmiles(smiles_string)\n",
    "        if mol is None:\n",
    "            print(f\"SMILES'dan molekül oluşturulurken hata: {smiles_string}\")\n",
    "        else:\n",
    "            display(MolToImage(mol))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
